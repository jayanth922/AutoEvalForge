# 🧠 AutoEvalForge

**Interactive Prompt Optimization + Evaluation + Auto-Retrain Framework for LLMs**

---

## 🗒️ Abstract

AutoEvalForge is a production-grade, full MLOps Level 4 platform for experimenting with prompts, evaluating model responses, and triggering fine-tuning automatically on poor-performing prompts. It supports advanced prompt engineering techniques (Chain-of-Thought, Few-Shot, ReAct), visual metrics (BLEU, BERTScore), and live deployment with a complete CI/CD pipeline using free cloud services.

---

## 📊 Live Demos (Coming Soon)

- 🔗 [Frontend (Vercel)](https://autoevalforge.vercel.app)
- 🔗 [Backend (Render)](https://autoevalforge-api.onrender.com)
- 🔗 [Model (HuggingFace)](https://huggingface.co/AutoEvalForge)
- 📽️ [Short Demo Video](https://youtube.com/xyz)
- 📽️ [Full Presentation (Team)](https://youtube.com/xyz-long)

---

## 🧑‍🤝‍🧑 Team Members

| Name | Role |
|------|------|
| Alice | Frontend UX + Prompt Engineering |
| Bob | Backend APIs + Model Evaluation |
| You | Model Training + CI/CD + MLOps Integration |

---

## 📁 Project Structure

- `frontend/`: React UI with prompt tools and evaluation dashboards
- `backend/`: FastAPI backend for inference, evaluation, and training
- `training/`: Model finetuning on datasets like SQuAD and SamSum
- `infra/`: CI/CD workflows, cloud deployment hooks
- `notebooks/`: Visualizations, analysis, and testing

---

## 📦 Model Details

- Base Models: `google/flan-t5-small`, `tiiuae/falcon`, `mistralai/Mistral-7B-Instruct`
- Tasks: Summarization, Q&A, Code Explanation, Roleplay
- Metrics: BLEU, BERTScore, Token Usage, Inference Cost
- Visualization: TensorBoard + Weights & Biases (W&B)

---

## ⚙️ MLOps Features

| Level | Capabilities |
|-------|--------------|
| 2️⃣ | Automated Training Pipeline |
| 3️⃣ | Automated Deployment with CI/CD |
| 4️⃣ | Monitoring, Drift Detection, Retraining, Metric Dashboards |

---

## 📌 Future Plans

- ✅ Prompt leaderboard + feedback loop
- ✅ Token + cost estimators
- ✅ Model drift graph
- ✅ Auto-CoT + Reflection support
- ✅ TPU deployment bonus (if compute permits)

---

## 📚 References & Credits

- [BLEU/BERTScore](https://huggingface.co/spaces/evaluate-metric)
- [MLOps Resources](https://github.com/visenger/awesome-mlops)
- [Prompting Strategies](https://github.com/f/awesome-chatgpt-prompts)
- [SQuAD Dataset](https://rajpurkar.github.io/SQuAD-explorer/)
